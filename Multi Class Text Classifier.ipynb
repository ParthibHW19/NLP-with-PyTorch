{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Parthib2009 - GovTech Text Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7AmyUGplXKd",
        "colab_type": "text"
      },
      "source": [
        "## GovTech Text Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz5sG5mUlXKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, TabularDataset, LabelField\n",
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "question = Field(tokenize = 'spacy')\n",
        "agency = LabelField(sequential=False)\n",
        "\n",
        "fields = {\"Question Asked\": (\"q\", question), \"Agency\": (\"s\", agency)}\n",
        "\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "        path=\"/content/drive/My Drive/gov\", # the root directory where the data lies\n",
        "        train='train_small.csv', test=\"test.csv\",\n",
        "        format='csv',\n",
        "        fields=fields # if your csv header has a header, make sure to pass this to ensure it doesn't get processed as data!\n",
        "        )\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f6ahYSOKZso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5384a95a-be8a-42a0-e783-2264d804a839"
      },
      "source": [
        "train_data[0].__dict__.keys()\n",
        "train_data[0].__dict__.values()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([['Hi', 'how', 'many', 'demerit', 'points', 'do', 'I', 'have'], 'SPF'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Dmyk5Ge8LK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db0b2edb-0b53-4dd3-8201-accfb2a1cb61"
      },
      "source": [
        "valid_data[0].__dict__.keys()\n",
        "valid_data[0].__dict__.values()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([['Other', 'employment', 'income', 'include', 'oversea', 'allowance'], 'IRAS IIT'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyRLkJmCIWdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "654897cf-8794-4bee-f5a3-b21a1a767255"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fQ-ShzQlXKm",
        "colab_type": "text"
      },
      "source": [
        "# Build the vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMVDWGQ6lXKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "question.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "agency.build_vocab(train_data)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Aut1VKlXKp",
        "colab_type": "text"
      },
      "source": [
        "# Next, we check the Agency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKRHM6ONlXKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8bcc92cd-a2aa-4ed1-d137-435b8958aa1d"
      },
      "source": [
        "print(agency.vocab.stoi)\n",
        "len(agency.vocab)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fe5b021e048>, {'IRAS IIT': 0, 'ICA': 1, 'LTA': 2, 'ACRA': 3, 'SPF': 4, 'MINDEF': 5, 'SSG': 6, 'MOE': 7, 'IRAS GST': 8, 'AVA': 9})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9APRTAlXKs",
        "colab_type": "text"
      },
      "source": [
        "# Set up the iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdOwEB6elXKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    sort = False, #don't sort test/validation data\n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Lp9YSdlXKv",
        "colab_type": "text"
      },
      "source": [
        "# Build CNN model. Can try with other model like RNN, Bidirectional RNN etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWE-yTolXKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        text = text.permute(1, 0)\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6aSZWwa5_8W",
        "colab_type": "text"
      },
      "source": [
        "#Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOu93MaolXK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(question.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [1,2]\n",
        "OUTPUT_DIM = len(agency.vocab)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = question.vocab.stoi[question.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqN0GFbmlXK2",
        "colab_type": "text"
      },
      "source": [
        "# Check the number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0W5WXUylXK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8de289dd-d0f1-4181-efaa-28ee86a17536"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 718,210 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9kpIOpilXK5",
        "colab_type": "text"
      },
      "source": [
        "# Load pre-trained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQDp81uylXK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "74077e6e-728f-45fd-b195-6a7b38028729"
      },
      "source": [
        "pretrained_embeddings = question.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.1897,  0.0500,  0.1908,  ..., -0.3980,  0.4765, -0.1598],\n",
              "        ...,\n",
              "        [-0.5068, -0.8909,  0.0254,  ...,  1.6284,  0.1772, -0.7119],\n",
              "        [ 0.3256, -0.1760,  0.5735,  ..., -0.1452,  0.6097, -2.6922],\n",
              "        [ 0.0323,  0.2468,  0.0765,  ..., -0.0374,  0.3347, -0.1959]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7aTrZpqlXK8",
        "colab_type": "text"
      },
      "source": [
        "# Then zero the initial weights of the unknown and padding tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w372usIklXK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = question.vocab.stoi[question.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QadeCo6KlXK_",
        "colab_type": "text"
      },
      "source": [
        "# Use CrossEntropyLoss for loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZxPGd78lXK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOGoUQ9dlXLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_b0jK9ClXLE",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFv7fvK3lXLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.q)\n",
        "        \n",
        "        loss = criterion(predictions, batch.s)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, batch.s)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNk3eOnElXLH",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TqURXtlXLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.q)\n",
        "            \n",
        "            loss = criterion(predictions, batch.s)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.s)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0T8xdWJlXLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNKPqRhHlXLN",
        "colab_type": "text"
      },
      "source": [
        "# Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SQBujtlMlXLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "245705d1-9a06-4b7c-c011-dee37f7c1f0d"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'govtech-text-classifier.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 1.391 | Train Acc: 55.48%\n",
            "\t Val. Loss: 0.903 |  Val. Acc: 71.59%\n",
            "Epoch: 02 | Epoch Time: 1m 1s\n",
            "\tTrain Loss: 0.803 | Train Acc: 75.71%\n",
            "\t Val. Loss: 0.726 |  Val. Acc: 78.31%\n",
            "Epoch: 03 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 0.586 | Train Acc: 82.33%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 79.73%\n",
            "Epoch: 04 | Epoch Time: 1m 1s\n",
            "\tTrain Loss: 0.464 | Train Acc: 85.83%\n",
            "\t Val. Loss: 0.712 |  Val. Acc: 80.33%\n",
            "Epoch: 05 | Epoch Time: 1m 5s\n",
            "\tTrain Loss: 0.350 | Train Acc: 89.27%\n",
            "\t Val. Loss: 0.725 |  Val. Acc: 80.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0U3F6lZlXLP",
        "colab_type": "text"
      },
      "source": [
        "#Run the model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSDa4k1IlXLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eea8dd2a-9a87-42d4-b0a2-ce154e347f5e"
      },
      "source": [
        "model.load_state_dict(torch.load('govtech-text-classifier.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.674 | Test Acc: 80.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbu2-hRvlXLS",
        "colab_type": "text"
      },
      "source": [
        "# Inference the model  with sample questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wnm_M3xlXLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_class(model, sentence, min_len = 4):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [question.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVqCsnZGlXLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "448d4055-689b-4e0c-f198-e4629f29da85"
      },
      "source": [
        "pred_class = predict_class(model, \"who can claim for skill future\")\n",
        "print(f'Predicted class is: {pred_class} = {agency.vocab.itos[pred_class]}')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class is: 6 = SSG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwMPLLXflXLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e63cf759-dd30-4c15-d6cf-011958595f4c"
      },
      "source": [
        "pred_class = predict_class(model, \"Why I cannot update my rent property\")\n",
        "print(f'Predicted class is: {pred_class} = {agency.vocab.itos[pred_class]}')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class is: 0 = IRAS IIT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NykRQejlXLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6212f98a-9414-4f85-dfbb-7a0d7d41bd27"
      },
      "source": [
        "pred_class = predict_class(model, \"Extend passport\")\n",
        "print(f'Predicted class is: {pred_class} = {agency.vocab.itos[pred_class]}')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class is: 1 = ICA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAeeZQmulXLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89b70aa1-259f-436f-d790-49ae5820c6c8"
      },
      "source": [
        "pred_class = predict_class(model, \"I lost my escooter\")\n",
        "print(f'Predicted class is: {pred_class} = {agency.vocab.itos[pred_class]}')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class is: 2 = LTA\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}